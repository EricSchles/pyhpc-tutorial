{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_start": true,
       "slide_type": "slide"
      }
     },
     "source": [
      "<style>\n",
      "    h1{\n",
      "        text-align:center;\n",
      "    }\n",
      "    h2{\n",
      "        text-align:center;\n",
      "        font-variant:small-caps;\n",
      "    }\n",
      "</style>\n",
      "# Scaling Python\n",
      "\n",
      "## Aron Ahmadia\n",
      "## [![Creative Commons License](http://mirrors.creativecommons.org/presskit/buttons/88x31/svg/by.svg)](http://creativecommons.org/licenses/by/3.0/deed.en_US)  "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_start": true,
       "slide_type": "slide"
      }
     },
     "source": [
      "## Acknowledgements\n",
      "\n",
      "* [mpi4py](http://code.google.com/p/mpi4py/) is a [Cythonized](http://www.cython.org/) wrapper around [MPI](http://www.mpi-forum.org/) originally developed by [Lisandro Dalcin](http://plus.google.com/107621373684536061961/about), CONICET\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_start": true,
       "slide_type": "slide"
      }
     },
     "source": [
      "## Slideshow Setup Code"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_start": false,
       "slide_type": "-"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_start": true,
       "slide_type": "slide"
      }
     },
     "source": [
      "## Connecting to MPI via IPython\n",
      "\n",
      "To run the examples in parallel, you must run the command:\n",
      "\n",
      "`ipcluster start --engines=MPI --n 4` \n",
      "\n",
      "Or use notebook Appendix_03_Launch_MPI_Engines \n",
      "(if you are using the VMs or have this configured for your environment).\n",
      "\n",
      "Then execute the next cell:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.parallel import Client\n",
      "c = Client()\n",
      "view = c[:]\n",
      "\n",
      "%load_ext parallelmagic\n",
      "view.activate()\n",
      "view.block = True"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_start": false,
       "slide_step": true
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_start": true,
       "slide_type": "slide"
      }
     },
     "source": [
      "---\n",
      "\n",
      "The Message Passing Model\n",
      "-------------------------------------\n",
      "\n",
      "* a process is (traditionally) a program counter for instructions and an address space for data\n",
      "* processes may have multiple threads (program counters and associated stacks) sharing a single address space\n",
      "* message passing is for communication among processes, which have separate address spaces\n",
      "* interprocess communication consists of\n",
      "  \n",
      "  - synchronization\n",
      "  - movement of data from one process's address space to another's\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_start": true,
       "slide_type": "slide"
      }
     },
     "source": [
      "---\n",
      "\n",
      "Why MPI?\n",
      "-------------------------------------\n",
      "<!--====-->\n",
      "\n",
      "* **communicators** encapsulate communication spaces for library safety\n",
      "* **datatypes** reduce copying costs and permit heterogeneity\n",
      "* multiple **communication modes** allow more control of memory buffer management\n",
      "* extensive **collective operations** for scalable global communication\n",
      "* **process topologies** permit efficient process placement, user views of process layout\n",
      "* **profiling interface** encourages portable tools\n",
      "\n",
      "It Scales!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_start": true,
       "slide_type": "slide"
      }
     },
     "source": [
      "---\n",
      "\n",
      "MPI - Quick Review\n",
      "-------------------------------------\n",
      "\n",
      "* processes can be collected into **groups**\n",
      "* each message is sent in a **context**, and must be received in the same context\n",
      "* a  **communicator** encapsulates a context for a specific group\n",
      "* a given program may have many communicators with any level of overlap\n",
      "* two initial communicators\n",
      " \n",
      "  - ``MPI_COMM_WORLD`` (all processes)\n",
      "  - ``MPI_COMM_SELF`` (current process)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_start": true,
       "slide_type": "slide"
      }
     },
     "source": [
      "---\n",
      "First Example: Hello World\n",
      "-------------------------------------\n",
      "\n",
      "For interactive convenience, we load the parallel magic extensions and make this view\n",
      "the active one for the automatic parallelism magics.\n",
      "\n",
      "This is not necessary and in production codes likely won't be used, as the engines will \n",
      "load their own MPI codes separately.  But it makes it easy to illustrate everything from\n",
      "within a single notebook here."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.parallel import Client\n",
      "c = Client()\n",
      "view = c[:]\n",
      "\n",
      "%load_ext parallelmagic\n",
      "view.activate()\n",
      "view.block = True"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_start": false,
       "slide_step": true,
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_start": false,
       "slide_step": true,
       "slide_type": "slide"
      }
     },
     "source": [
      "Use the autopx magic to make the rest of this cell execute on the engines instead\n",
      "of locally"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%autopx"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_start": false
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_start": false,
       "slide_step": true,
       "slide_type": "fragment"
      }
     },
     "source": [
      "With autopx enabled, the next cell will actually execute *entirely on each engine*:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "## Hello World"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from mpi4py import MPI\n",
      "\n",
      "size = MPI.COMM_WORLD.Get_size()\n",
      "rank = MPI.COMM_WORLD.Get_rank()\n",
      "name = MPI.Get_processor_name()\n",
      "\n",
      "print(\"Hello World! I am process %d of %d on %s.\\n\" % (rank, size, name))"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_start": false,
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_start": false,
       "slide_type": "slide"
      }
     },
     "source": [
      "---\n",
      "\n",
      "Functionality\n",
      "-------------------------------------\n",
      "\n",
      "* There are hundreds of functions in the MPI standard, not all of them are necessarily available in MPI4Py, most commonly used are\n",
      "* No need to call MPI_Init() or MPI_Finalize()\n",
      " - MPI_Init() is called when you import the module\n",
      " - MPI_Finalize() is called before the Python process ends\n",
      "* To launch:\n",
      "    mpirun --np < number of process > -machinefile < hostlist > python < my MPI4Py python script >\n",
      "* IPython automatically handles calling mpirun for you with the `ipcluster` command"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_start": true,
       "slide_step": false,
       "slide_type": "slide"
      }
     },
     "source": [
      "## MPI Basic (Blocking) Send\n",
      "\n",
      "\n",
      "```\n",
      "   int MPI_Send(void* buf, int count, MPI_Datatype type, \n",
      "   int dest, int tag, MPI_Comm comm)\n",
      "```\n",
      "\n",
      "### mpi4py\n",
      "\n",
      "```\n",
      "  Comm.Send(self, buf, int dest=0, int tag=0)\n",
      "  Comm.send(self, obj=None, int dest=0, int tag=0)\n",
      "```"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_start": true,
       "slide_type": "slide"
      }
     },
     "source": [
      "## MPI Basic (Blocking) Recv\n",
      "\n",
      "```\n",
      "   int MPI_Recv(void* buf, int count, MPI_Datatype type, \n",
      "   int source, int tag, MPI_Comm comm, MPI_Status status)\n",
      "```\n",
      "\n",
      "### mpi4py\n",
      "\n",
      "```\n",
      "  comm.Recv(self, buf, source=0, tag=0, status=None)\n",
      "  comm.recv(self, obj=None, source=0, tag=0, status=None)\n",
      "```"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_start": true,
       "slide_type": "slide"
      }
     },
     "source": [
      "## Send/Receive Example (lowercase convenience methods)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from mpi4py import MPI\n",
      "\n",
      "comm = MPI.COMM_WORLD\n",
      "rank = comm.Get_rank()\n",
      "\n",
      "if rank == 0:\n",
      "   data = {'a': 7, 'b': 3.14}\n",
      "   comm.send(data, dest=1, tag=11)\n",
      "elif rank == 1:\n",
      "   data = comm.recv(source=0, tag=11)\n",
      "   print data"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_start": false,
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_start": true,
       "slide_type": "slide"
      }
     },
     "source": [
      "---\n",
      "Send/Receive Example (MPI API on numpy)\n",
      "-------------------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from mpi4py import MPI\n",
      "import numpy\n",
      "\n",
      "comm = MPI.COMM_WORLD\n",
      "rank = comm.Get_rank()\n",
      "\n",
      "# pass explicit MPI datatypes\n",
      "if rank == 0:\n",
      "   data = numpy.arange(1000, dtype='i')\n",
      "   comm.Send([data, MPI.INT], dest=1, tag=77)\n",
      "elif rank == 1:\n",
      "   data = numpy.empty(1000, dtype='i')\n",
      "   comm.Recv([data, MPI.INT], source=0, tag=77)\n",
      "\n",
      "# or take advantage of automatic MPI datatype discovery\n",
      "if rank == 0:\n",
      "   data = numpy.arange(10, dtype=numpy.float64)\n",
      "   comm.Send(data, dest=1, tag=13)\n",
      "elif rank == 1:\n",
      "   data = numpy.empty(10, dtype=numpy.float64)\n",
      "   comm.Recv(data, source=0, tag=13)\n",
      "   print data"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_start": false,
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_start": true,
       "slide_type": "slide"
      }
     },
     "source": [
      "## Synchronization\n",
      "\n",
      "```\n",
      "   int MPI_Barrier(MPI_Comm comm)\n",
      "```\n",
      "\n",
      "### mpi4py\n",
      "\n",
      "```\n",
      "   comm.Barrier(self)\n",
      "   comm.barrier(self)\n",
      "```"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from mpi4py import MPI\n",
      "\n",
      "comm = MPI.COMM_WORLD\n",
      "rank = comm.Get_rank()\n",
      "\n",
      "for r_id in range(comm.Get_size()):\n",
      "    if rank == r_id:\n",
      "        print \"Hello from proc:\", rank\n",
      "    comm.Barrier()\n"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_start": false,
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_start": true,
       "slide_type": "slide"
      }
     },
     "source": [
      "## Timing and Profiling\n",
      "\n",
      "the elapsed (wall-clock) time between two points in an MPI program can be computed using MPI_Wtime:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "t1 = MPI.Wtime()\n",
      "t2 = MPI.Wtime()\n",
      "print(\"time elapsed is: %e\\n\" % (t2-t1))"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_start": false,
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_start": true,
       "slide_type": "slide"
      }
     },
     "source": [
      "## Broadcast Example\n",
      "\n",
      "```\n",
      "   int MPI_Bcast(void *buf, int count, MPI_Datatype type, \n",
      "   int root, MPI_Comm comm)\n",
      "```\n",
      "\n",
      "### mpi4py\n",
      "\n",
      "``` \n",
      "  comm.Bcast(self, buf, root=0)\n",
      "  comm.bcast(self, obj=None, root=0)\n",
      "```"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from mpi4py import MPI\n",
      "\n",
      "comm = MPI.COMM_WORLD\n",
      "rank = comm.Get_rank()\n",
      "\n",
      "if rank == 0:\n",
      "   data = {'key1' : [7, 2.72, 2+3j],\n",
      "           'key2' : ( 'abc', 'xyz')}\n",
      "else:\n",
      "   data = None\n",
      "data = comm.bcast(data, root=0)\n",
      "print \"bcast finished and data \\\n",
      " on rank %d is: \\n\" % comm.rank, data\n"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_start": false,
       "slide_step": true,
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_start": true,
       "slide_type": "slide"
      }
     },
     "source": [
      "## Scatter Example"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from mpi4py import MPI\n",
      "\n",
      "comm = MPI.COMM_WORLD\n",
      "size = comm.Get_size()\n",
      "rank = comm.Get_rank()\n",
      "\n",
      "if rank == 0:\n",
      "   data = [(i+1)**2 for i in range(size)]\n",
      "else:\n",
      "   data = None\n",
      "data = comm.scatter(data, root=0)\n",
      "assert data == (rank+1)**2\n",
      "print \"data on rank %d is: \"%comm.rank, data"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_start": false,
       "slide_step": true,
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_start": true,
       "slide_type": "slide"
      }
     },
     "source": [
      "## Gather (and Barrier) Example"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from mpi4py import MPI\n",
      "\n",
      "comm = MPI.COMM_WORLD\n",
      "size = comm.Get_size()\n",
      "rank = comm.Get_rank()\n",
      "\n",
      "data = (rank+1)**2\n",
      "print \"before gather, data on \\\n",
      "  rank %d is: \"%rank, data\n",
      "\n",
      "comm.Barrier()\n",
      "data = comm.gather(data, root=0)\n",
      "if rank == 0:\n",
      "   for i in range(size):\n",
      "       assert data[i] == (i+1)**2\n",
      "else:\n",
      "   assert data is None\n",
      "print \"data on rank: %d is: \"%rank, data"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_start": false,
       "slide_step": true,
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_start": true,
       "slide_type": "slide"
      }
     },
     "source": [
      "## Collective Examples"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_start": true,
       "slide_type": "slide"
      }
     },
     "source": [
      "## Reduce Example"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from mpi4py import MPI\n",
      "comm = MPI.COMM_WORLD\n",
      "\n",
      "sendmsg = comm.rank\n",
      "recvmsg1 = comm.reduce(sendmsg, op=MPI.SUM, root=0)\n",
      "recvmsg2 = comm.allreduce(sendmsg)\n",
      "\n",
      "print recvmsg2"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_start": false,
       "slide_step": true,
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_start": true,
       "slide_type": "slide"
      }
     },
     "source": [
      "---\n",
      "Compute Pi Example\n",
      "-------------------\n",
      "<!--====-->\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from mpi4py import MPI\n",
      "import math\n",
      "\n",
      "def compute_pi(n, start=0, step=1):\n",
      "    h = 1.0 / n\n",
      "    s = 0.0\n",
      "    for i in range(start, n, step):\n",
      "        x = h * (i + 0.5)\n",
      "        s += 4.0 / (1.0 + x**2)\n",
      "    return s * h\n",
      "\n",
      "comm = MPI.COMM_WORLD\n",
      "nprocs = comm.Get_size()\n",
      "myrank = comm.Get_rank()\n",
      "if myrank == 0:\n",
      "    n = 10\n",
      "else:\n",
      "    n = None\n",
      "\n",
      "n = comm.bcast(n, root=0)\n",
      "\n",
      "mypi = compute_pi(n, myrank, nprocs)\n",
      "\n",
      "pi = comm.reduce(mypi, op=MPI.SUM, root=0)\n",
      "\n",
      "if myrank == 0:\n",
      "    error = abs(pi - math.pi)\n",
      "    print (\"pi is approximately %.16f, error is %.16f\" % (pi, error))"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_start": false,
       "slide_step": true,
       "slide_type": "subslide"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_start": true,
       "slide_type": "slide"
      }
     },
     "source": [
      "---\n",
      "Mandelbrot Set Example\n",
      "-------------------\n",
      "<!--====-->\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def mandelbrot (x, y, maxit):\n",
      "    c = x + y*1j\n",
      "    z = 0 + 0j\n",
      "    it = 0\n",
      "    while abs(z) < 2 and it < maxit:\n",
      "        z = z**2 + c\n",
      "        it += 1\n",
      "    return it\n",
      "\n",
      "x1, x2 = -2.0, 1.0\n",
      "y1, y2 = -1.0, 1.0\n",
      "w, h = 150, 100\n",
      "maxit = 127\n",
      "\n",
      "from mpi4py import MPI\n",
      "import numpy\n",
      "  \n",
      "comm = MPI.COMM_WORLD\n",
      "size = comm.Get_size()\n",
      "rank = comm.Get_rank()\n",
      "\n",
      "# number of rows to compute here\n",
      "N = h // size + (h % size > rank)\n",
      "\n",
      "# first row to compute here\n",
      "start = comm.scan(N)-N\n",
      "\n",
      "# array to store local result\n",
      "Cl = numpy.zeros([N, w], dtype='i')\n",
      "\n",
      "# compute owned rows\n",
      "\n",
      "dx = (x2 - x1) / w\n",
      "dy = (y2 - y1) / h\n",
      "\n",
      "for i in range(N):\n",
      "    y = y1 + (i + start) * dy\n",
      "    for j in range(w):\n",
      "        x = x1 + j * dx\n",
      "        Cl[i, j] = mandelbrot(x, y, maxit)\n",
      "\n",
      "# gather results at root (process 0)\n",
      "counts = comm.gather(N, root=0)\n",
      "C = None\n",
      "if rank == 0:\n",
      "    C = numpy.zeros([h, w], dtype='i')\n",
      "\n",
      "rowtype = MPI.INT.Create_contiguous(w)\n",
      "rowtype.Commit()\n",
      "\n",
      "comm.Gatherv(sendbuf=[Cl, MPI.INT], recvbuf=[C, (counts, None), rowtype],root=0)\n",
      "\n",
      "rowtype.Free()"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_start": false,
       "slide_step": true,
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_start": false,
       "slide_type": "fragment"
      }
     },
     "source": [
      "We now need to \"pull\" the C array for plotting so we disable autopx. Make sure to re-enable it later on"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%autopx"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_start": false,
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# CC is an array of C from all ranks, so we use CC[0]\n",
      "CC = view['C']\n",
      "ranks = view['rank']\n",
      "\n",
      "# Do the plotting\n",
      "from matplotlib import pyplot\n",
      "# Some magic to get to MPI4PY rank 0, not necessarily engine id 0\n",
      "pyplot.imshow(CC[ranks.index(0)], aspect='equal')\n",
      "pyplot.spectral()\n",
      "pyplot.show()"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_start": false,
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_start": false,
       "slide_type": "fragment"
      }
     },
     "source": [
      "Toggle autopx back"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%autopx"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_start": false,
       "slide_type": "fragment"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_start": true,
       "slide_type": "slide"
      }
     },
     "source": [
      "---\n",
      "Advanced Capabilities\n",
      "----------------------------\n",
      "\n",
      "Other features supported by mpi4py\n",
      "\n",
      "* dynamic process spawning: Spawn(), Connect() and Disconnect()\n",
      "* one sided communication: Put(), Get(), Accumulate()\n",
      "* MPI-IO: Open(), Close(), Get_view() and Set_view()"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_start": true,
       "slide_type": "slide"
      }
     },
     "source": [
      "---\n",
      "More Comprehensive mpi4py Tutorials\n",
      "----------------------------\n",
      "<!--====-->\n",
      "\n",
      "* basics - http://mpi4py.scipy.org/docs/usrman/tutorial.html\n",
      "* advanced - http://www.bu.edu/pasi/files/2011/01/Lisandro-Dalcin-mpi4py.pdf\n",
      "\n",
      "Interesting Scalable Applications and Tools\n",
      "---------------------------------------------\n",
      "* PyTrilinos - http://trilinos.sandia.gov/packages/pytrilinos/\n",
      "* petsc4py - http://code.google.com/p/petsc4py/\n",
      "* PyClaw - http://numerics.kaust.edu.sa/pyclaw/\n",
      "* GPAW - https://wiki.fysik.dtu.dk/gpaw/"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}