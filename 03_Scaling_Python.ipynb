{
 "metadata": {
  "name": "03_Scaling_Python"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_start": true
      }
     },
     "source": [
      "<style>\n",
      "    h1{\n",
      "        text-align:center;\n",
      "    }\n",
      "    h2{\n",
      "        text-align:center;\n",
      "        font-variant:small-caps;\n",
      "    }\n",
      "</style>\n",
      "# Scaling Python\n",
      "# Python in HPC\n",
      "\n",
      "##Supercomputing 2012\n",
      "\n",
      "Presenters:\n",
      "\n",
      "Andy R. Terrel, PhD  \n",
      "Texas Advanced Computing Center  \n",
      "University of Texas at Austin  \n",
      "\n",
      "Travis Oliphant, PhD  \n",
      "Continuum Analytics\n",
      "\n",
      "Aron Ahmadia, PhD  \n",
      "Supercomputing Laboratory  \n",
      "King Abdullah University of Science and Technoglogy\n",
      "\n",
      "![TACC Logo](/files/figures/TACC_logo.png)\n",
      "![Continuum Logo](/files/figures/continuum.png)\n",
      "![KAUST Logo](/files/figures/kaust.png)\n",
      "\n",
      "The contents of this tutorial are distributed under the CC-BY Creative Commons License \n",
      "\n",
      "[![Creative Commons License](http://i.creativecommons.org/l/by/3.0/88x31.png)](http://creativecommons.org/licenses/by/3.0/deed.en_US) \n",
      "  "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_start": true
      }
     },
     "source": [
      "---\n",
      "\n",
      "## About This Tutorial\n",
      "\n",
      "### PyHPC Tutorial on GitHub\n",
      "\n",
      "These presentation materials are part of a continuously updated tutorial on Python for High Performance Computing.  To get the presentation materials as they were delivered today, please use the SC2012 tag on github.  Future versions of this presentation will be found at:\n",
      "\n",
      "https://github.com/pyhpc/pyhpc-tutorial\n",
      "\n",
      "Please set all permanent bookmarks to this URL.\n",
      "\n",
      "### Direct download of this SC2012 presentation\n",
      "You can download a zip or tar ball from the [github SC2012 tag](https://github.com/pyHPC/pyhpc-tutorial/tags):\n",
      "\n",
      "```\n",
      "wget --no-check-certificate https://github.com/pyhpc/pyhpc-tutorial/zipball/SC2012\n",
      "wget --no-check-certificate https://github.com/pyhpc/pyhpc-tutorial/tarball/SC2012\n",
      "```\n",
      "\n",
      "### \n",
      "2) Checkout from git\n",
      "\n",
      "```\n",
      "git clone https://github.com/pyhpc/pyhpc-tutorial.git\n",
      "```\n",
      "\n",
      "### Viewing the read-only version of this presentation on nbviewer: \n",
      "\n",
      "* http://nbviewer.ipython.org/urls/raw.github.com/pyhpc/pyhpc-tutorial/master/03_Scaling_Python.ipynb"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_start": true
      }
     },
     "source": [
      "---\n",
      "\n",
      "## Interacting with the Tutorial Slides\n",
      "\n",
      "This tutorial is an interactive worksheet designed to encourage you to try out the lessons during the demonstration.  If you are looking at the PDF version of these slides, we encourage you to download the updated version (see previous slide) and try the interactive version.\n",
      "\n",
      "To run the interactive version of this notebook, you will need a Python 2.7 environment including: \n",
      "\n",
      "* IPython version >= 13.0\n",
      "* numpy version >= 1.6\n",
      "* scipy >= 0.10\n",
      "* matplotlib >= 1.0.0\n",
      "* mpi4py >= 1.2\n",
      "\n",
      "Move to the directory containing the tarball and execute:\n",
      "\n",
      "    ipcluster start --engines=MPI --n 4\n",
      "    ipython notebook --pylab=inline\n",
      "\n",
      "If you are installing the packages yourself, Continuum Analytics (disclaimer, Travis Oliphant is CEO of this company) provides both free community as well as professional versions of the Anaconda installer, which provides all the packages you will need for this portion of the tutorial. The installer is available from the [Anaconda download page at Continuum Analytics](https://store.continuum.io/cshop/anaconda).\n",
      "\n",
      "You are also welcome to use Enthought's Python Distribution (free for Academic users), available from the [EPD download page at Enthought](http://www.enthought.com/products/epd.php).\n",
      "\n",
      "Unfortunately, you will need to upgrade your EPD's IPython to 0.13 if you go this route, and this may be non-trivial, please see the [Enthought discussion thread here](https://mail.enthought.com/pipermail/epd-users/2012-August/000800.html)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_start": true
      }
     },
     "source": [
      "--- \n",
      "\n",
      "## Using the Texas Advanced Computing Center IPython Notebooks\n",
      "\n",
      "You will need a modern web browser to interact with the TACC nodes, there are no other requirements.\n",
      "\n",
      "### TACC IPython Notebooks\n",
      "* http://pyhpc01.tacc.utexas.edu/\n",
      "* http://pyhpc02.tacc.utexas.edu/\n",
      "* http://pyhpc03.tacc.utexas.edu/\n",
      "* http://pyhpc04.tacc.utexas.edu/\n",
      "* http://pyhpc05.tacc.utexas.edu/\n",
      "* http://pyhpc06.tacc.utexas.edu/\n",
      "* http://pyhpc07.tacc.utexas.edu/\n",
      "* http://pyhpc08.tacc.utexas.edu/\n",
      "* http://pyhpc09.tacc.utexas.edu/\n",
      "* http://pyhpc10.tacc.utexas.edu/\n",
      "\n",
      "The TACC nodes will not be available after this workshop."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_start": true
      }
     },
     "source": [
      "---\n",
      "## Presentation mode\n",
      "The slideshow mode is only supported by an IPython development branch version. If you would like to write your own slideshows (the notebooks will work regardless of slideshow capabilities), you will need to install Matthias Bussonnier's slideshow_metadata branch.  Here are some sample command-line instructions.\n",
      "\n",
      "    #!/bin/bash\n",
      "    git clone carreau git://github.com/Carreau/ipython.git # Matthias' IPython fork\n",
      "    git checkout origin/slideshow_metadata                 # Select the right branch\n",
      "    python setup.py develop                                # Install the development version\n",
      "    ipython notebook                                       # Check out the slideshows!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_start": true
      }
     },
     "source": [
      "---\n",
      "## Slideshow Setup Code"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# The below command starts pylab inline mode, which simplifies syntax for many common \n",
      "# scientific computing commands.  All commands starting with % are IPython extensions.\n",
      "%pylab inline\n",
      "\n",
      "# The following two lines of code load the slideshow extension and start it,\n",
      "# you only need to run these if you are writing or running your own slideshow\n",
      "\n",
      "%load_ext slidemode\n",
      "%slideshow_mode"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_start": false
      }
     },
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_start": true
      }
     },
     "source": [
      "---\n",
      "\n",
      "Acknowledgements\n",
      "-------------------------------------\n",
      "<!--====-->\n",
      "\n",
      "* Much of this tutorial adapts slide material from [William Gropp](http://www.cs.uiuc.edu/~wgropp/), University of Illinois and [Lisandro Dalcin](http://plus.google.com/107621373684536061961/about), CONICET\n",
      "* [mpi4py](http://code.google.com/p/mpi4py/) is a [Cythonized](http://www.cython.org/) wrapper around [MPI](http://www.mpi-forum.org/) originally developed by [Lisandro Dalcin](http://plus.google.com/107621373684536061961/about), CONICET\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_start": true
      }
     },
     "source": [
      "---\n",
      "\n",
      "Connecting to MPI via IPython\n",
      "-------------------------------------\n",
      "\n",
      "To run the examples in parallel, you must run the command:\n",
      "\n",
      "`ipcluster start --engines=MPI --n 4` \n",
      "\n",
      "Or use notebook Appendix_03_Launch_MPI_Engines \n",
      "(if you are using the VMs or have this configured for your environment).\n",
      "\n",
      "Then execute the next cell:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.parallel import Client\n",
      "c = Client()\n",
      "view = c[:]\n",
      "\n",
      "%load_ext parallelmagic\n",
      "view.activate()\n",
      "view.block = True"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_start": false,
       "slide_step": true
      }
     },
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_start": true
      }
     },
     "source": [
      "# A Quick Review of Concepts of Scalability"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_start": true
      }
     },
     "source": [
      "---\n",
      "\n",
      "# The Multiple Forms of Parallelism\n",
      "\n",
      "* **instruction** - multiple program instructions are simultaneously dispatched in a pipeline or to multiple execution units (superscalar)\n",
      "* **data** - the same program instructions are carried out simultaneously on multiple data items (SIMD)\n",
      "* **task** - different program instructions on different data (MIMD)\n",
      "* **collective** - single program, multiple data, not necessarily synchronized at individual operation level (SPMD)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_start": false,
       "slide_step": true
      }
     },
     "source": [
      "> *This part of the tutorial focuses on data and collective parallelism*"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_start": true
      }
     },
     "source": [
      "---\n",
      "\n",
      "# Parallel Architectures\n",
      "<!--====-->\n",
      "\n",
      "* All modern supercomputing architectures are composed of distributed memory compute nodes connected over toroidal networks\n",
      "  \n",
      "  - close mapping to physically n-dimensional problems\n",
      "  - efficient algorithms exist for local point-to-point and collective communications across toroids\n",
      "\n",
      "* We expect to see higher dimensional interconnects and power-efficient networks that consume less power when not sending traffic\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_start": true
      }
     },
     "source": [
      "---\n",
      "\n",
      "# Parallel Programming Paradigms\n",
      "<!--====-->\n",
      "\n",
      "* a parallel programming paradigm is a specific approach to exploiting parallelism in hardware\n",
      "* many programming paradigms are very tightly coupled to the hardware beneath!\n",
      "  \n",
      " - CUDA assumes large register files, Same Instruction Multiple Thread parallelism, and a mostly flat, structured memory model, matching the underlying GPU hardware\n",
      "\n",
      " - OpenMP exposes loop level parallelism with a fork/join model, assumes the presence of shared memory and atomics\n",
      "\n",
      " - OpenCL tries to generalize CUDA, but still assumes a 'coprocessor' approach, where kernels are shipped from a master core to worker cores\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_start": true
      }
     },
     "source": [
      "---\n",
      "\n",
      "The Message Passing Model\n",
      "-------------------------------------\n",
      "\n",
      "* a process is (traditionally) a program counter for instructions and an address space for data\n",
      "* processes may have multiple threads (program counters and associated stacks) sharing a single address space\n",
      "* message passing is for communication among processes, which have separate address spaces\n",
      "* interprocess communication consists of\n",
      "  \n",
      "  - synchronization\n",
      "  - movement of data from one process's address space to another's\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_start": true
      }
     },
     "source": [
      "---\n",
      "\n",
      "Why MPI?\n",
      "-------------------------------------\n",
      "<!--====-->\n",
      "\n",
      "* **communicators** encapsulate communication spaces for library safety\n",
      "* **datatypes** reduce copying costs and permit heterogeneity\n",
      "* multiple **communication modes** allow more control of memory buffer management\n",
      "* extensive **collective operations** for scalable global communication\n",
      "* **process topologies** permit efficient process placement, user views of process layout\n",
      "* **profiling interface** encourages portable tools\n",
      "\n",
      "It Scales!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_start": true
      }
     },
     "source": [
      "---\n",
      "\n",
      "Python + MPI Does It Scale?\n",
      "-------------------------------------\n",
      "\n",
      "![concurrency](/files/figures/does_it_scale.png)\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_start": true
      }
     },
     "source": [
      "---\n",
      "\n",
      "The Scalability of Python + MPI\n",
      "-------------------------------------\n",
      "\n",
      "![concurrency](/files/figures/euler_weak_scaling.png)\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_start": true
      }
     },
     "source": [
      "---\n",
      "\n",
      "MPI - Quick Review\n",
      "-------------------------------------\n",
      "\n",
      "* processes can be collected into **groups**\n",
      "* each message is sent in a **context**, and must be received in the same context\n",
      "* a  **communicator** encapsulates a context for a specific group\n",
      "* a given program may have many communicators with any level of overlap\n",
      "* two initial communicators\n",
      " \n",
      "  - ``MPI_COMM_WORLD`` (all processes)\n",
      "  - ``MPI_COMM_SELF`` (current process)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_start": true
      }
     },
     "source": [
      "---\n",
      "First Example: Hello World\n",
      "-------------------------------------\n",
      "\n",
      "For interactive convenience, we load the parallel magic extensions and make this view\n",
      "the active one for the automatic parallelism magics.\n",
      "\n",
      "This is not necessary and in production codes likely won't be used, as the engines will \n",
      "load their own MPI codes separately.  But it makes it easy to illustrate everything from\n",
      "within a single notebook here."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.parallel import Client\n",
      "c = Client()\n",
      "view = c[:]\n",
      "\n",
      "%load_ext parallelmagic\n",
      "view.activate()\n",
      "view.block = True"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_start": false,
       "slide_step": true
      }
     },
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_start": false,
       "slide_step": true
      }
     },
     "source": [
      "Use the autopx magic to make the rest of this cell execute on the engines instead\n",
      "of locally"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%autopx"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_start": false
      }
     },
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_start": false,
       "slide_step": true
      }
     },
     "source": [
      "With autopx enabled, the next cell will actually execute *entirely on each engine*:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from mpi4py import MPI\n",
      "\n",
      "size = MPI.COMM_WORLD.Get_size()\n",
      "rank = MPI.COMM_WORLD.Get_rank()\n",
      "name = MPI.Get_processor_name()\n",
      "\n",
      "print(\"Hello World! I am process %d of %d on %s.\\n\" % (rank, size, name))"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_start": false
      }
     },
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_start": true
      }
     },
     "source": [
      "---\n",
      "\n",
      "Communicators\n",
      "-------------------------------------\n",
      "<!--====-->\n",
      "\n",
      "* processes can be collected into **groups**\n",
      "* each message is sent in a **context**, and must be received in the same context\n",
      "* a  **communicator** encapsulates a context for a specific group\n",
      "* a given program may have many communicators with any level of overlap\n",
      "* two initial communicators\n",
      " \n",
      "  - ``MPI_COMM_WORLD`` (all processes)\n",
      "  - ``MPI_COMM_SELF`` (current process)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_start": true
      }
     },
     "source": [
      "---\n",
      "\n",
      "Datatypes\n",
      "-------------------------------------\n",
      "<!--====-->\n",
      "\n",
      "* the data in a message to send or receive is described by address, count and datatype\n",
      "* a datatype is recursively defined as:\n",
      "\n",
      "  + predefined, corresponding to a data type from the language (e.g., ``MPI_INT``, ``MPI_DOUBLE``)\n",
      "  + a contiguous, strided block, or indexed array of blocks of MPI datatypes\n",
      "  + an arbitrary structure of datatypes\n",
      "\n",
      "* there are MPI functions to construct custom datatypes"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_start": false
      }
     },
     "source": [
      "---\n",
      "\n",
      "Tags\n",
      "-------------------------------------\n",
      "<!--====-->\n",
      "\n",
      "* messages are sent with an accompanying user-defined integer tag to assist the receiving process in identifying the message\n",
      "* messages can be screened at the receiving end by specifying the expected tag, or not screened by using ``MPI_ANY_TAG`` "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_start": false
      }
     },
     "source": [
      "---\n",
      "\n",
      "Functionality\n",
      "-------------------------------------\n",
      "\n",
      "* There are hundreds of functions in the MPI standard, not all of them are necessarily available in MPI4Py, most commonly used are\n",
      "* No need to call MPI_Init() or MPI_Finalize()\n",
      " - MPI_Init() is called when you import the module\n",
      " - MPI_Finalize() is called before the Python process ends\n",
      "* To launch:\n",
      "    mpirun --np < number of process > -machinefile < hostlist > python < my MPI4Py python script >\n",
      "* IPython automatically handles calling mpirun for you with the `ipcluster` command"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_start": true,
       "slide_step": false
      }
     },
     "source": [
      "---\n",
      "\n",
      "MPI Basic (Blocking) Send\n",
      "-------------------------------------\n",
      "<!--====-->\n",
      "\n",
      "```\n",
      "   int MPI_Send(void* buf, int count, MPI_Datatype type, \n",
      "   int dest, int tag, MPI_Comm comm)\n",
      "```\n",
      "\n",
      "Python (mpi4py)\n",
      "\n",
      "```\n",
      "  Comm.Send(self, buf, int dest=0, int tag=0)\n",
      "  Comm.send(self, obj=None, int dest=0, int tag=0)\n",
      "```"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_start": true
      }
     },
     "source": [
      "---\n",
      "\n",
      "MPI Basic (Blocking) Recv\n",
      "-------------------------------------\n",
      "<!--====-->\n",
      "\n",
      "```\n",
      "   int MPI_Recv(void* buf, int count, MPI_Datatype type, \n",
      "   int source, int tag, MPI_Comm comm, MPI_Status status)\n",
      "```\n",
      "\n",
      "Python (mpi4py)\n",
      "\n",
      "```\n",
      "  comm.Recv(self, buf, int source=0, int tag=0, \n",
      "  Status status=None)\n",
      "  comm.recv(self, obj=None, int source=0, \n",
      "  int tag=0, Status status=None)\n",
      "```"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_start": true
      }
     },
     "source": [
      "---\n",
      "Send/Receive Example (lowercase convenience methods)\n",
      "-------------------------------------\n",
      "<!--====-->\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from mpi4py import MPI\n",
      "\n",
      "comm = MPI.COMM_WORLD\n",
      "rank = comm.Get_rank()\n",
      "\n",
      "if rank == 0:\n",
      "   data = {'a': 7, 'b': 3.14}\n",
      "   comm.send(data, dest=1, tag=11)\n",
      "elif rank == 1:\n",
      "   data = comm.recv(source=0, tag=11)\n",
      "   print data"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_start": false
      }
     },
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_start": true
      }
     },
     "source": [
      "---\n",
      "Send/Receive Example (MPI API on numpy)\n",
      "-------------------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from mpi4py import MPI\n",
      "import numpy\n",
      "\n",
      "comm = MPI.COMM_WORLD\n",
      "rank = comm.Get_rank()\n",
      "\n",
      "# pass explicit MPI datatypes\n",
      "if rank == 0:\n",
      "   data = numpy.arange(1000, dtype='i')\n",
      "   comm.Send([data, MPI.INT], dest=1, tag=77)\n",
      "elif rank == 1:\n",
      "   data = numpy.empty(1000, dtype='i')\n",
      "   comm.Recv([data, MPI.INT], source=0, tag=77)\n",
      "\n",
      "# or take advantage of automatic MPI datatype discovery\n",
      "if rank == 0:\n",
      "   data = numpy.arange(100, dtype=numpy.float64)\n",
      "   comm.Send(data, dest=1, tag=13)\n",
      "elif rank == 1:\n",
      "   data = numpy.empty(100, dtype=numpy.float64)\n",
      "   comm.Recv(data, source=0, tag=13)\n",
      "   print data"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_start": false
      }
     },
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_start": true
      }
     },
     "source": [
      "---\n",
      "Synchronization\n",
      "-------------------------------------\n",
      "<!--====-->\n",
      "\n",
      "```\n",
      "   int MPI_Barrier(MPI_Comm comm)\n",
      "```\n",
      "\n",
      "Python (mpi4py)\n",
      "\n",
      "```\n",
      "   comm.Barrier(self)\n",
      "   comm.barrier(self)\n",
      "```"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from mpi4py import MPI\n",
      "\n",
      "comm = MPI.COMM_WORLD\n",
      "rank = comm.Get_rank()\n",
      "\n",
      "for r_id in range(comm.Get_size()):\n",
      "    if rank == r_id:\n",
      "        print \"Hello from proc:\", rank\n",
      "    comm.Barrier()\n"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_start": false
      }
     },
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_start": true
      }
     },
     "source": [
      "---\n",
      "\n",
      "Timing and Profiling\n",
      "-------------------------------------\n",
      "<!--====-->\n",
      "\n",
      "the elapsed (wall-clock) time between two points in an MPI program can be computed using MPI_Wtime:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "t1 = MPI.Wtime()\n",
      "t2 = MPI.Wtime()\n",
      "print(\"time elapsed is: %e\\n\" % (t2-t1))"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_start": false
      }
     },
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_start": true
      }
     },
     "source": [
      "---\n",
      "Send/Receive Example (lowercase convenience methods)\n",
      "-------------------------------------\n",
      "<!--====-->\n",
      "\n",
      "![broadcast_scatter_gather](/files/figures/broadcast_scatter_gather.png)\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_start": true
      }
     },
     "source": [
      "---\n",
      "Broadcast Example\n",
      "-------------------------------------\n",
      "<!--====-->\n",
      "\n",
      "```\n",
      "   int MPI_Bcast(void *buf, int count, MPI_Datatype type, \n",
      "   int root, MPI_Comm comm)\n",
      "```\n",
      "\n",
      "Python (mpi4py)\n",
      "\n",
      "``` \n",
      "  comm.Bcast(self, buf, int root=0)\n",
      "  comm.bcast(self, obj=None, int root=0)\n",
      "```"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from mpi4py import MPI\n",
      "\n",
      "comm = MPI.COMM_WORLD\n",
      "rank = comm.Get_rank()\n",
      "\n",
      "if rank == 0:\n",
      "   data = {'key1' : [7, 2.72, 2+3j],\n",
      "           'key2' : ( 'abc', 'xyz')}\n",
      "else:\n",
      "   data = None\n",
      "data = comm.bcast(data, root=0)\n",
      "print \"bcast finished and data \\\n",
      " on rank %d is: \"%comm.rank, data\n"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_start": false,
       "slide_step": true
      }
     },
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_start": true
      }
     },
     "source": [
      "\n",
      "---\n",
      "Scatter Example:\n",
      "-------------------------------------\n",
      "<!--====-->\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from mpi4py import MPI\n",
      "\n",
      "comm = MPI.COMM_WORLD\n",
      "size = comm.Get_size()\n",
      "rank = comm.Get_rank()\n",
      "\n",
      "if rank == 0:\n",
      "   data = [(i+1)**2 for i in range(size)]\n",
      "else:\n",
      "   data = None\n",
      "data = comm.scatter(data, root=0)\n",
      "assert data == (rank+1)**2\n",
      "print \"data on rank %d is: \"%comm.rank, data"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_start": false,
       "slide_step": true
      }
     },
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_start": true
      }
     },
     "source": [
      "\n",
      "---\n",
      "Gather (and Barrier) Example:\n",
      "-------------------------------------\n",
      "<!--====-->\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from mpi4py import MPI\n",
      "\n",
      "comm = MPI.COMM_WORLD\n",
      "size = comm.Get_size()\n",
      "rank = comm.Get_rank()\n",
      "\n",
      "data = (rank+1)**2\n",
      "print \"before gather, data on \\\n",
      "  rank %d is: \"%rank, data\n",
      "\n",
      "comm.Barrier()\n",
      "data = comm.gather(data, root=0)\n",
      "if rank == 0:\n",
      "   for i in range(size):\n",
      "       assert data[i] == (i+1)**2\n",
      "else:\n",
      "   assert data is None\n",
      "print \"data on rank: %d is: \"%rank, data"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_start": false,
       "slide_step": true
      }
     },
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_start": true
      }
     },
     "source": [
      "---\n",
      "Collective Example\n",
      "-------------------\n",
      "<!--====-->\n",
      "\n",
      "![reduce_scan](/files/figures/reduce_scan.png)\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_start": true
      }
     },
     "source": [
      "\n",
      "---\n",
      "Reduce Example:\n",
      "-------------------------------------\n",
      "<!--====-->\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from mpi4py import MPI\n",
      "comm = MPI.COMM_WORLD\n",
      "\n",
      "sendmsg = comm.rank\n",
      "\n",
      "recvmsg1 = comm.reduce(sendmsg, op=MPI.SUM, root=0)\n",
      "\n",
      "recvmsg2 = comm.allreduce(sendmsg)\n",
      "print recvmsg2"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_start": false,
       "slide_step": true
      }
     },
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_start": true
      }
     },
     "source": [
      "---\n",
      "Compute Pi Example\n",
      "-------------------\n",
      "<!--====-->\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from mpi4py import MPI\n",
      "import math\n",
      "\n",
      "def compute_pi(n, start=0, step=1):\n",
      "    h = 1.0 / n\n",
      "    s = 0.0\n",
      "    for i in range(start, n, step):\n",
      "        x = h * (i + 0.5)\n",
      "        s += 4.0 / (1.0 + x**2)\n",
      "    return s * h\n",
      "\n",
      "comm = MPI.COMM_WORLD\n",
      "nprocs = comm.Get_size()\n",
      "myrank = comm.Get_rank()\n",
      "if myrank == 0:\n",
      "    n = 10\n",
      "else:\n",
      "    n = None\n",
      "\n",
      "n = comm.bcast(n, root=0)\n",
      "\n",
      "mypi = compute_pi(n, myrank, nprocs)\n",
      "\n",
      "pi = comm.reduce(mypi, op=MPI.SUM, root=0)\n",
      "\n",
      "if myrank == 0:\n",
      "    error = abs(pi - math.pi)\n",
      "    print (\"pi is approximately %.16f, error is %.16f\" % (pi, error))"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_start": false,
       "slide_step": true
      }
     },
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_start": true
      }
     },
     "source": [
      "---\n",
      "Mandelbrot Set Example\n",
      "-------------------\n",
      "<!--====-->\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def mandelbrot (x, y, maxit):\n",
      "    c = x + y*1j\n",
      "    z = 0 + 0j\n",
      "    it = 0\n",
      "    while abs(z) < 2 and it < maxit:\n",
      "        z = z**2 + c\n",
      "        it += 1\n",
      "    return it\n",
      "\n",
      "x1, x2 = -2.0, 1.0\n",
      "y1, y2 = -1.0, 1.0\n",
      "w, h = 150, 100\n",
      "maxit = 127\n",
      "\n",
      "from mpi4py import MPI\n",
      "import numpy\n",
      "  \n",
      "comm = MPI.COMM_WORLD\n",
      "size = comm.Get_size()\n",
      "rank = comm.Get_rank()\n",
      "\n",
      "# number of rows to compute here\n",
      "N = h // size + (h % size > rank)\n",
      "\n",
      "# first row to compute here\n",
      "start = comm.scan(N)-N\n",
      "\n",
      "# array to store local result\n",
      "Cl = numpy.zeros([N, w], dtype='i')\n",
      "\n",
      "# compute owned rows\n",
      "\n",
      "dx = (x2 - x1) / w\n",
      "dy = (y2 - y1) / h\n",
      "\n",
      "for i in range(N):\n",
      "    y = y1 + (i + start) * dy\n",
      "    for j in range(w):\n",
      "        x = x1 + j * dx\n",
      "        Cl[i, j] = mandelbrot(x, y, maxit)\n",
      "\n",
      "# gather results at root (process 0)\n",
      "counts = comm.gather(N, root=0)\n",
      "C = None\n",
      "if rank == 0:\n",
      "    C = numpy.zeros([h, w], dtype='i')\n",
      "\n",
      "rowtype = MPI.INT.Create_contiguous(w)\n",
      "rowtype.Commit()\n",
      "\n",
      "comm.Gatherv(sendbuf=[Cl, MPI.INT], recvbuf=[C, (counts, None), rowtype],root=0)\n",
      "\n",
      "rowtype.Free()"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_start": false,
       "slide_step": true
      }
     },
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_start": false
      }
     },
     "source": [
      "We now need to \"pull\" the C array for plotting so we disable autopx. Make sure to re-enable it later on"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%autopx"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_start": false
      }
     },
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# CC is an array of C from all ranks, so we use CC[0]\n",
      "CC = view['C']\n",
      "ranks = view['rank']\n",
      "\n",
      "# Do the plotting\n",
      "from matplotlib import pyplot\n",
      "# Some magic to get to MPI4PY rank 0, not necessarily engine id 0\n",
      "pyplot.imshow(CC[ranks.index(0)], aspect='equal')\n",
      "pyplot.spectral()\n",
      "pyplot.show()"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_start": false
      }
     },
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_start": false
      }
     },
     "source": [
      "Toggle autopx back"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%autopx"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_start": false
      }
     },
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_start": true
      }
     },
     "source": [
      "---\n",
      "Advanced Capabilities\n",
      "----------------------------\n",
      "\n",
      "Other features supported by mpi4py\n",
      "\n",
      "* dynamic process spawning: Spawn(), Connect() and Disconnect()\n",
      "* one sided communication: Put(), Get(), Accumulate()\n",
      "* MPI-IO: Open(), Close(), Get_view() and Set_view()"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_start": true
      }
     },
     "source": [
      "---\n",
      "More Comprehensive mpi4py Tutorials\n",
      "----------------------------\n",
      "<!--====-->\n",
      "\n",
      "* basics - http://mpi4py.scipy.org/docs/usrman/tutorial.html\n",
      "* advanced - http://www.bu.edu/pasi/files/2011/01/Lisandro-Dalcin-mpi4py.pdf\n",
      "\n",
      "Interesting Scalable Applications and Tools\n",
      "---------------------------------------------\n",
      "* PyTrilinos - http://trilinos.sandia.gov/packages/pytrilinos/\n",
      "* petsc4py - http://code.google.com/p/petsc4py/\n",
      "* PyClaw - http://numerics.kaust.edu.sa/pyclaw/\n",
      "* GPAW - https://wiki.fysik.dtu.dk/gpaw/\n",
      "\n",
      "Addressing the Import Problem\n",
      "-----------------------------\n",
      "* Static compilation from Pat Marion - https://github.com/patmarion/NumpyBuiltinExample\n",
      "* Path caching from Asher Langton - https://github.com/langton/MPI_Import\n",
      "* ld.so interception plus zipimport-enabled path caching from Aron Ahmadia, Jed Brown, and William Scullin - https://github.com/ahmadia/collfs\n",
      "\n",
      "--> See Appendix 01 References for more resources\n",
      "----------------------------------------------"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}